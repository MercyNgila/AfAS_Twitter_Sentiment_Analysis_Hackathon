{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMof5HLmlo7+iHzcGEYbgxl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MercyNgila/AfAS_Twitter_Sentiment_Analysis_Hackathon/blob/main/twitter_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Collecting and Cleaning Data"
      ],
      "metadata": {
        "id": "YV_uuLvfoqsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "\n",
        "\n",
        "*   Use twitter API to collect data\n",
        "*   Extract tweet \n",
        "*   Perform Preprocessing\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G3pbZTzVo20m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install tweepy --upgrade"
      ],
      "metadata": {
        "id": "0gOqdceqzxJa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAiUVtK7oUs4",
        "outputId": "f42e2aa7-ab2f-451c-8f09-2050d7825c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Import relevant libraries\n",
        "\n",
        "import tweepy\n",
        "import pandas as pd\n",
        "import csv\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import nltk \n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "tokenizer = ToktokTokenizer()\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Twitter credentials\n",
        "api_key = 'cYqgqqPHPgcCPnPTbJdW9qDBy'\n",
        "api_secret_key = 'NnPeHrjnottsOKKmmUdFE1fXv8kiEkaXPM4ape5YZgWvYUyNpi'\n",
        "access_token = '1067416516424097792-gNvNl8tVxlHdbNYJOefNS2ryr7xiZL'\n",
        "access_token_secret = 'RgZxasoylpYPBtwqygjRLTdUOwFrlH8B4ADptq6ksRvWe'"
      ],
      "metadata": {
        "id": "VnQqtSgHxTkt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We then import the credentials\n",
        "#import twitter_credentials as tc\n",
        "\n",
        "# Create an authentication object of the AuthHandler class by passing in the credentials\n",
        "auth = tweepy.OAuthHandler(api_key, api_secret_key)\n",
        "\n",
        "# Set the access tokens to complete the authentication process\n",
        "auth.set_access_token(access_token, access_token_secret)"
      ],
      "metadata": {
        "id": "9rszvcI0pWol"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Autheticating information\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True)"
      ],
      "metadata": {
        "id": "8N_SKEpkq_Iv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your search words in accordance with the basic filtering rules\n",
        "search_words = \"maandamano OR azimio OR raila OR ruto OR gachagua OR maandamanomonday\"\n",
        "\n",
        "# We also want to exclude retweets and replies as this may sway results\n",
        "my_search = search_words + \" -filter:retweets\" + \" -filter:replies\" "
      ],
      "metadata": {
        "id": "NhY7VY9GzXcZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Twitter data is stored in a Tweet object which we've called tweets\n",
        "#tweets = api.search_tweets(q = my_search,lang = \"en\",tweet_mode = \"extended\",count = 100)"
      ],
      "metadata": {
        "id": "efLJZti91Q1Z"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YxwOjFmf1T2_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}